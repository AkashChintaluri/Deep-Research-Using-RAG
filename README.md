# ğŸ”¬ ArXiv Research Assistant

A sophisticated **Retrieval-Augmented Generation (RAG)** system that enables intelligent search and conversation with 497+ ArXiv astronomy research papers. Built with modern web technologies and deployed on AWS.

![Python](https://img.shields.io/badge/Python-3.11+-blue)
![React](https://img.shields.io/badge/React-19.1.1-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue)
![AWS](https://img.shields.io/badge/AWS-App%20Runner%20%7C%20Amplify-orange)

## ğŸŒŸ Features

### ğŸ§  **Intelligent RAG System**
- **Semantic Search**: Find papers using natural language queries
- **Conversational AI**: Chat with your research papers using OpenAI GPT-4
- **Hybrid Search**: Combines vector similarity (FAISS/Pinecone) with PostgreSQL full-text search
- **Context-Aware**: Maintains conversation history for better responses

### ğŸ“š **Comprehensive Paper Database**
- **497+ Astronomy Papers**: Processed from ArXiv astro-ph category
- **Full-Text Extraction**: Complete PDF text extraction and processing
- **Smart Chunking**: Papers split into 200-600 token chunks for optimal search
- **Metadata Rich**: Titles, authors, abstracts, and full content indexed

### ğŸ¨ **Modern Web Interface**
- **React Frontend**: Beautiful, responsive UI with Tailwind CSS
- **Real-time Chat**: Interactive conversation interface
- **Paper Browser**: Browse and explore research papers
- **LaTeX Rendering**: Mathematical equations rendered with MathJax
- **Export Features**: Download conversations as PDF or Markdown

### â˜ï¸ **Production-Ready Architecture**
- **AWS Deployment**: Backend on App Runner, Frontend on Amplify
- **Scalable Database**: PostgreSQL with optimized indexes
- **Vector Storage**: FAISS for local, Pinecone for cloud vector search
- **Dockerized**: Containerized for easy deployment
- **Health Monitoring**: Comprehensive health checks and logging

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    subgraph "Frontend (AWS Amplify)"
        A[React App] --> B[Chat Interface]
        A --> C[Paper Browser]
        A --> D[Export Features]
    end
    
    subgraph "Backend (AWS App Runner)"
        E[FastAPI Server] --> F[RAG Service]
        E --> G[Search Service]
        E --> H[Export Service]
    end
    
    subgraph "Data Layer"
        I[PostgreSQL] --> J[Paper Metadata]
        I --> K[Full-Text Search]
        L[FAISS Index] --> M[Vector Embeddings]
        N[Pinecone] --> O[Cloud Vectors]
    end
    
    subgraph "AI Services"
        P[OpenAI GPT-4] --> Q[Response Generation]
        R[Sentence Transformers] --> S[Embeddings]
    end
    
    A --> E
    F --> I
    F --> L
    F --> N
    F --> P
    G --> R
```

## ğŸ“ Project Structure

```
Codemate/
â”œâ”€â”€ ğŸ“ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ ğŸ app.py                 # Main FastAPI application
â”‚   â”œâ”€â”€ ğŸ“ src/                   # Source code
â”‚   â”‚   â”œâ”€â”€ ğŸ“ api/               # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py          # Chat/conversation endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ search.py        # Search endpoints
â”‚   â”‚   â”‚   â””â”€â”€ health.py        # Health check endpoints
â”‚   â”‚   â”œâ”€â”€ ğŸ“ services/          # Business logic services
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_service.py   # RAG conversation service
â”‚   â”‚   â”‚   â”œâ”€â”€ search_service.py # Search orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ postgres_service.py # Database operations
â”‚   â”‚   â”‚   â”œâ”€â”€ faiss_service.py # Vector search
â”‚   â”‚   â”‚   â”œâ”€â”€ pinecone_service.py # Cloud vector search
â”‚   â”‚   â”‚   â”œâ”€â”€ export_service.py # PDF/Markdown export
â”‚   â”‚   â”‚   â””â”€â”€ conversation_service.py # Chat history
â”‚   â”‚   â”œâ”€â”€ ğŸ“ models/            # Data models
â”‚   â”‚   â””â”€â”€ ğŸ“ core/              # Configuration
â”‚   â”œâ”€â”€ ğŸ“ data/                  # Research papers data
â”‚   â”‚   â”œâ”€â”€ ğŸ“ pdfs/             # 497 PDF files
â”‚   â”‚   â””â”€â”€ ğŸ“ processed/        # Processed data
â”‚   â”œâ”€â”€ ğŸ“ scripts/              # Utility scripts
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt      # Python dependencies
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile           # Container configuration
â”‚   â””â”€â”€ ğŸ“„ apprunner.yaml       # AWS App Runner config
â”œâ”€â”€ ğŸ“ frontend/                  # React Frontend
â”‚   â”œâ”€â”€ ğŸ“ src/                  # Source code
â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/       # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ Chatbot.jsx     # Main chat interface
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageList.jsx # Message display
â”‚   â”‚   â”‚   â”œâ”€â”€ PaperList.jsx   # Paper browser
â”‚   â”‚   â”‚   â””â”€â”€ PaperDetail.jsx # Paper details
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ App.jsx          # Main app component
â”‚   â”‚   â””â”€â”€ ğŸ“„ config.js        # Environment configuration
â”‚   â”œâ”€â”€ ğŸ“„ package.json         # Node.js dependencies
â”‚   â”œâ”€â”€ ğŸ“„ vite.config.js       # Vite build configuration
â”‚   â””â”€â”€ ğŸ“„ amplify.yml          # AWS Amplify config
â”œâ”€â”€ ğŸ“„ .gitignore               # Git ignore rules
â””â”€â”€ ğŸ“„ README.md               # This file
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Node.js 16+**
- **PostgreSQL 15+**
- **Docker** (for containerization)

### Local Development

#### 1. **Backend Setup**

```bash
# Navigate to backend
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp env.example .env
# Edit .env with your database and API keys

# Start the server
python app.py
```

#### 2. **Frontend Setup**

```bash
# Navigate to frontend
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

#### 3. **Access the Application**

- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file in the `backend/` directory:

```bash
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=Codemate
DB_USER=postgres
DB_PASSWORD=your-password

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4o

# Pinecone Configuration (Optional)
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_INDEX_NAME=arxiv-papers

# Azure OpenAI (Alternative)
USE_AZURE_OPENAI=false
AZURE_OPENAI_API_KEY=your-azure-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
```

## ğŸ“¡ API Endpoints

### **Search Endpoints**
- `GET /api/v1/search` - Search papers with query parameters
- `POST /api/v1/search` - Search papers with request body

### **Chat Endpoints**
- `POST /api/v1/chat` - Start or continue a conversation
- `GET /api/v1/chat/health` - Check RAG service health
- `POST /api/v1/chat/export/{format}` - Export conversation (PDF/Markdown)

### **Health & Stats**
- `GET /api/v1/health` - Overall system health
- `GET /api/v1/stats` - Database statistics

### **Example API Usage**

```bash
# Search for papers about black holes
curl -X POST "http://localhost:8000/api/v1/search" \
  -H "Content-Type: application/json" \
  -d '{"query": "black holes", "n_results": 5, "search_type": "faiss"}'

# Start a conversation
curl -X POST "http://localhost:8000/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{"query": "Tell me about exoplanet detection methods", "conversation_id": null}'
```

## â˜ï¸ AWS Deployment

### **Backend to AWS App Runner**

1. **Build and push Docker image to ECR:**
```bash
# Make deployment script executable
chmod +x deploy-to-aws.sh

# Run deployment (requires AWS CLI configured)
./deploy-to-aws.sh
```

2. **Create App Runner service:**
   - Use the ECR image URL from the script output
   - Configure environment variables
   - Set health check path: `/api/v1/health`

### **Frontend to AWS Amplify**

1. **Connect GitHub repository to Amplify**
2. **Configure build settings:**
   - Root directory: `frontend/`
   - Build specification: `amplify.yml`
3. **Add environment variable:**
   - `REACT_APP_API_URL`: Your App Runner URL

### **Database Setup**

Create an RDS PostgreSQL instance:
```bash
aws rds create-db-instance \
  --db-instance-identifier arxiv-research-db \
  --db-instance-class db.t3.micro \
  --engine postgres \
  --engine-version 15.4 \
  --master-username postgres \
  --master-user-password your-secure-password \
  --allocated-storage 20 \
  --publicly-accessible true
```

## ğŸ¯ Usage Examples

### **Research Queries**
- "What are the latest discoveries about black holes?"
- "Explain gravitational wave detection methods"
- "Find papers about exoplanet atmospheres"
- "What is dark matter and how do we study it?"

### **Conversation Features**
- **Follow-up Questions**: Ask clarifying questions about papers
- **Paper Exploration**: Click on referenced papers to explore them
- **Export Conversations**: Download your research sessions as PDF or Markdown
- **Context Awareness**: The AI remembers your conversation history

## ğŸ” Search Types

### **1. Vector Search (FAISS/Pinecone)**
- Semantic similarity search
- Finds papers with similar concepts
- Best for: "papers like this one"

### **2. Full-Text Search (PostgreSQL)**
- Keyword-based search
- Searches titles, abstracts, and full text
- Best for: specific terms and phrases

### **3. Hybrid Search**
- Combines both approaches
- Provides most comprehensive results
- Best for: complex research queries

## ğŸ› ï¸ Development

### **Adding New Papers**

```bash
# Process new PDFs
cd backend
python scripts/process_pdfs.py --input-dir /path/to/new/pdfs

# Generate embeddings
python scripts/generate_embeddings.py

# Update search index
python scripts/create_faiss_index.py
```

### **Customizing Search**

Modify search parameters in `backend/src/core/config.py`:
- Chunk size and overlap
- Embedding model
- Search result limits
- Similarity thresholds

## ğŸ“Š Performance

- **Search Speed**: Sub-second response times
- **Paper Processing**: ~3-4 seconds per PDF
- **Memory Usage**: ~2GB for full dataset
- **Storage**: ~500MB for processed data

## ğŸ”’ Security

- **Environment Variables**: Sensitive data stored in environment variables
- **CORS Configuration**: Properly configured for production
- **Input Validation**: All inputs validated and sanitized
- **Rate Limiting**: Built-in protection against abuse

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request


## ğŸ™ Acknowledgments

- **ArXiv**: For providing the research papers
- **OpenAI**: For the GPT-4 language model
- **Hugging Face**: For the sentence-transformers library
- **FastAPI**: For the excellent web framework
- **React**: For the frontend framework

## ğŸ“ Support

- **Issues**: Report bugs and feature requests on GitHub
- **Documentation**: Check the `/docs` endpoint for API documentation
- **Health Check**: Monitor system status at `/api/v1/health`

---